{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Linear Regression - Normalization\n",
    "In today's lesson we will explore new kinds of linear regression, in the form of Lasso and Ridge Regression.\n",
    "Your task will include:\n",
    "- creating a train/test split of the Boston Dataset\n",
    "- implementing Lasso Regression\n",
    "- implementing Ridge Regression\n",
    "- comparing results\n",
    "\n",
    "As you can see, today's lesson will be done using Jupyter, a Python Package that allows us to write interactive Notebooks divided in Cells. Each cell can be executed independetely, however you should remember that each time you execute a cell it's as if you are continuing the code run previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Train/Test splits of the Dataset\n",
    "It is common practice to divide the data you are working with into different sections (called splits).\n",
    "This is particularly necessary when working with Deep Learning Methods, since they are sensible to overfitting.\n",
    "Overfitting means that a model learns especially well a set of data, but in return loses the ability to generalize, meaning it will perform worse with data it has never seen.\n",
    "\n",
    "Splitting the dataset in two will allow us to train a model on the train_split and test its performance on the test_split.\n",
    "\n",
    "### Tips for this task\n",
    "- We have already seen how to load the Boston Dataset and how to convert it to a Numpy matrix\n",
    "- SKLearn has a built in function to split datasets ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for general purposes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the boston dataset, create X and Y, the numpy arrays of data and target\n",
    "# remember to scale the data!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 13) (455,)\n",
      "(51, 13) (51,)\n"
     ]
    }
   ],
   "source": [
    "## generate X_train, X_test, y_train, y_test, the numpy arrays containing the split data and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Implement Ridge Regression, Lasso Regression, Least Square Regression\n",
    "In this section you are expected to implement the 3 kinds of linear regressions seen in class: Lasso, Ridge and Least Square Linear Regression.\n",
    "\n",
    "Additionally, we want to compare the performances between train_splits and test_splits. \n",
    "In particular, we want to train our models on the train splits, and then see their performances on both train_splits and test_splits, to capture the different ability to generalize.\n",
    "\n",
    "We want to compare different factors of the 3 methods:\n",
    "- Accuracy, using MSE and R2\n",
    "- Time taken to get the solution\n",
    "- The weight matrices (thetas)\n",
    "\n",
    "### Tips for this task(s)\n",
    "- We have seen how to calculate the time for regression, and the different scores\n",
    "- SKLearn has all the functions you are looking for ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1 - Regression and Results\n",
    "In this first part, you are tasked with implementing the 3 different regressions and to calculate the 3 scores seen in class (R2, MSE, MAE).\n",
    "- You must train the regressors on the train_split and calculate the results on the test_splits.\n",
    "- Which model is better?\n",
    "- Additionally, calculate the time it takes the 3 methods to get the weigth matrix. Which one is faster? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score Reg-Lin 0.7596438759923646\n",
      "MSE Reg-Lin 27.836948462205537\n",
      "R2 score Reg-Las 0.7136077540750553\n",
      "MSE Reg-Las 33.16864183387616\n",
      "R2 score Reg-Rid 0.7598825906763125\n",
      "MSE Reg-Rid 27.80930161783383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# confront results between regression methods\n",
    "\n",
    "# Standard Linear Regression\n",
    "reg_lin = LinearRegression()\n",
    "reg_lin.fit(X_train,y_train)\n",
    "pred_lin = reg_lin.predict(X_test)\n",
    "print(\"R2 score Reg-Lin\", r2_score(y_test, pred_lin))\n",
    "print(\"MSE Reg-Lin\", mean_squared_error(y_test, pred_lin))\n",
    "\n",
    "\n",
    "# Lasso Regression\n",
    "reg_las = Lasso()\n",
    "reg_las.fit(X_train,y_train)\n",
    "pred_las = reg_las.predict(X_test)\n",
    "print(\"R2 score Reg-Las\", r2_score(y_test, pred_las))\n",
    "print(\"MSE Reg-Las\", mean_squared_error(y_test, pred_las))\n",
    "\n",
    "# Ridge Regression\n",
    "reg_rid = Ridge()\n",
    "reg_rid.fit(X_train,y_train)\n",
    "pred_rid = reg_rid.predict(X_test)\n",
    "print(\"R2 score Reg-Rid\", r2_score(y_test, pred_rid))\n",
    "print(\"MSE Reg-Rid\", mean_squared_error(y_test, pred_rid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2\n",
    "In this subtask we want to compare the different weights that each model produces.\n",
    "You can use the weights calculated in the previous section to make your calculation, or you can re-calculate them.\n",
    "- Look at the weights of the matrixes: are there features that tend to have a low absolute value?\n",
    "- Try and do regression on the same data with those features removed. Compare the results.\n",
    "- Use the whole dataset without splitting, to reduce randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Matrix\n",
      "[-0.87805578  1.12222753  0.23821264  0.68315784 -2.125061    2.8022863\n",
      "  0.0221266  -3.00390348  2.80007274 -2.1694357  -1.97367975  0.89755551\n",
      " -3.72367369]\n",
      "\n",
      "\n",
      "Lasso Matrix\n",
      "[-0.          0.         -0.          0.06926065 -0.          2.7530966\n",
      " -0.         -0.         -0.         -0.         -1.23066838  0.19489447\n",
      " -3.51999848]\n",
      "\n",
      "\n",
      "Ridge Matrix\n",
      "[-0.86933063  1.10692859  0.21283102  0.68738644 -2.09430916  2.81139193\n",
      "  0.01380454 -2.97670886  2.71683151 -2.09244825 -1.9642439   0.89737787\n",
      " -3.70804342]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confront the matrixes of the weights\n",
    "print('Linear Matrix')\n",
    "print(reg_lin.coef_)\n",
    "print('\\n\\nLasso Matrix')\n",
    "print(reg_las.coef_)\n",
    "print('\\n\\nRidge Matrix')\n",
    "print(reg_rid.coef_)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score Reg-Las 0.7136084936400932\n",
      "MSE Reg-Las 33.168556180831416\n",
      "R2 score Reg-Las 0.7136077540750553\n",
      "MSE Reg-Las 33.16864183387616\n"
     ]
    }
   ],
   "source": [
    "## Remove from the entire dataset the columns that Lasso sets to 0\n",
    "\n",
    "X_train_slim = X_train[:,reg_las.coef_ != 0]\n",
    "X_test_slim = X_test[:,reg_las.coef_ != 0]\n",
    "\n",
    "\n",
    "# compare Lasso regression on original data with Lasso regression on reduced data\n",
    "reg_las = Lasso()\n",
    "reg_las.fit(X_train_slim,y_train)\n",
    "pred_las = reg_las.predict(X_test_slim)\n",
    "print(\"R2 score Reg-Las\", r2_score(y_test, pred_las))\n",
    "print(\"MSE Reg-Las\", mean_squared_error(y_test, pred_las))\n",
    "\n",
    "reg_las = Lasso()\n",
    "reg_las.fit(X_train,y_train)\n",
    "pred_las = reg_las.predict(X_test)\n",
    "print(\"R2 score Reg-Las\", r2_score(y_test, pred_las))\n",
    "print(\"MSE Reg-Las\", mean_squared_error(y_test, pred_las))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c1368ead719bab1172f6be1cdedc075cc408ce16edb1ac759f3128a87e8e2e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
